{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"clean_zillow.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = wrangle.split_zillow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kmeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2fcc154d4d86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_longitude_latitude_houseage_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_longitude_latitude_houseage_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_longitude_latitude_houseage_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codeup-data-science/zillow_project_2021/Caitlyn/wrangle.py\u001b[0m in \u001b[0;36mprep_longitude_latitude_houseage_clusters\u001b[0;34m(some_dataframe)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprep_longitude_latitude_houseage_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     \u001b[0msome_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_cluster_longitude_latitude_houseage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0msome_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dummy_longitude_latitude_houseage_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msome_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codeup-data-science/zillow_project_2021/Caitlyn/wrangle.py\u001b[0m in \u001b[0;36mpredict_cluster_longitude_latitude_houseage\u001b[0;34m(some_dataframe)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cluster_longitude_latitude_houseage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     \u001b[0msome_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longitude_latitude_houseage_cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msome_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kmeans' is not defined"
     ]
    }
   ],
   "source": [
    "train = wrangle.prep_longitude_latitude_houseage_clusters(train)\n",
    "validate = wrangle.prep_longitude_latitude_houseage_clusters(validate)\n",
    "test = wrangle.prep_longitude_latitude_houseage_clusters(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm, \n",
    "            alpha=.5, color=\"mediumblue\", s=100, label=\"Model: LinearRegression\")\n",
    "m, b = np.polyfit(y_validate.logerror, y_validate.logerror_pred_lm, 1)\n",
    "plt.plot(y_validate.logerror, m*y_validate.logerror+b, color='limegreen', label='Line of Regrssion', linewidth=5)\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"yellow\", label='Baseline', linewidth=5)\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"cyan\", label='The Ideal Line: Predicted = Actual', linewidth=5)\n",
    "plt.title('Model: LinearRegression')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm-y_validate.logerror, \n",
    "            alpha=.5, color=\"mediumblue\", s=100, label=\"Model: LinearRegression\")\n",
    "plt.axhline(label=\"No Error\", color='black', linewidth=7)\n",
    "plt.title('Model: LinearRegression')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(3, 5, figsize=(8,16), sharey=True)\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.title(\"Comparing the Distribution of logerrors to Distributions of Predicted logerrors Linear Regression Models\")\n",
    "plt.xlabel(\"logerror\", size = 15)\n",
    "plt.ylabel(\"logerror Count\", size = 15)\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.hist(y_validate.logerror, color='cyan', alpha=.5,  ec='black')\n",
    "plt.title('Actual logerrors', size=15)\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.hist(y_validate.logerror_pred_lm, color='lawngreen', alpha=.5,  ec='black')\n",
    "plt.title('Model: LinearRegression', size=15)\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.hist(y_validate.logerror, color='lawngreen', alpha=.5, label=\"Actual Final logerrors\", ec='black')\n",
    "plt.hist(y_validate.logerror_pred_lm, color='cyan', alpha=.5, label=\"Model: LinearRegression\", ec='black')\n",
    "plt.title(\"All Graphs Stacked\", size=15)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression(normalize=True)\n",
    "lm.fit(X_test, y_test.logerror)\n",
    "y_test['logerror_pred_lm'] = lm.predict(X_test)\n",
    "rmse_test_lm = mean_squared_error(y_test.logerror, y_test.logerror_pred_lm)**(1/2)\n",
    "print(\"RMSE for OLS using LinearRegression Test Data: \", rmse_test_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score_baseline = r2_score(y_validate.logerror, y_validate.logerror_pred_median)\n",
    "r2_score_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score_ols = r2_score(y_validate.logerror, y_validate.logerror_pred_lm)\n",
    "r2_score_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, X_test, y_train, y_validate, y_test = wrangle.split_train_validate_test(train, validate, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need y_train and y_validate to be dataframes to append the new columns with predicted values. \n",
    "y_train = pd.DataFrame(y_train)\n",
    "    # turn it into a single pandas dataframe\n",
    "y_validate = pd.DataFrame(y_validate)\n",
    "    # wrap them as dataframes\n",
    "\n",
    "# 1. Predict logerror_pred_mean\n",
    "    # 2 different aselines of mean and medium\n",
    "logerror_pred_mean = y_train['logerror'].mean()\n",
    "y_train['logerror_pred_mean'] = logerror_pred_mean\n",
    "y_validate['logerror_pred_mean'] = logerror_pred_mean\n",
    "\n",
    "# 2. compute logerror_pred_median\n",
    "    # same process as mean (above)\n",
    "logerror_pred_median = y_train['logerror'].median()\n",
    "y_train['logerror_pred_median'] = logerror_pred_median\n",
    "y_validate['logerror_pred_median'] = logerror_pred_median\n",
    "\n",
    "# 3. RMSE of logerror_pred_mean\n",
    "rmse_train_mean = mean_squared_error(y_train.logerror, \n",
    "                                     y_train.logerror_pred_mean)**(1/2)\n",
    "    # stick with root mean square error\n",
    "        # not your only option but that is what we will be using here\n",
    "            # just because it is eaiest to us and explain\n",
    "    # remember when you call you it will be your y_true and y_pred\n",
    "rmse_validate_mean = mean_squared_error(y_validate.logerror, \n",
    "                                        y_validate.logerror_pred_mean)**(1/2)\n",
    "    # do the same thing for the validate set as done above for the train set\n",
    "    \n",
    "print(\"RMSE using Mean\\nTrain/In-Sample: \", round(rmse_train_mean, 2), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate_mean, 2))\n",
    "print(' ')\n",
    "# 4. RMSE of logerror_pred_median\n",
    "rmse_train_medium = mean_squared_error(y_train.logerror, \n",
    "                                       y_train.logerror_pred_median)**(1/2)\n",
    "\n",
    "rmse_validate_medium = mean_squared_error(y_validate.logerror, \n",
    "                                          y_validate.logerror_pred_median)**(1/2)\n",
    "\n",
    "print(\"RMSE using Median\\nTrain/In-Sample: \", round(rmse_train_medium, 2), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate_medium, 2))\n",
    "\n",
    "# median comes out a little higher than mean \n",
    "    # but a little lower than our validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lm = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm.fit(X_train, y_train.logerror)\n",
    "    # just call y_train.actual_target\n",
    "\n",
    "# predict train\n",
    "y_train['logerror_pred_lm'] = lm.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train_lm = mean_squared_error(y_train.logerror, y_train.logerror_pred_lm)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['logerror_pred_lm'] = lm.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate_lm = mean_squared_error(y_validate.logerror, y_validate.logerror_pred_lm)**(1/2)\n",
    "    # make sure you are using x_validate an not x_train\n",
    "\n",
    "print(\"RMSE for OLS using LinearRegression\\nTraining/In-Sample: \", rmse_train_lm, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_validate.head()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"Baseline: Predict Using Median\", (16, 9.5))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"The Ideal Line: Predicted = Actual\", (.5, 3.5), rotation=15.5)\n",
    "\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm, \n",
    "            alpha=.5, color=\"blue\", s=100, label=\"Model: LinearRegression\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Where are predictions more extreme? More modest?\")\n",
    "# plt.annotate(\"The polynomial model appears to overreact to noise\", (2.0, -10))\n",
    "# plt.annotate(\"The OLS model (LinearRegression)\\n appears to be most consistent\", (15.5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lars = LassoLars(alpha=1.0)\n",
    "    # what alpha is in this case\n",
    "        # kidn of that regualizer that make lasso a little bit different\n",
    "        # can go from 0 to infinity\n",
    "            # it will eventually stop changing the efficivicy of you model \n",
    "                # depenind on th enumber of features being fed in\n",
    "            # if alpha = 0 it is the same thing as a los model\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lars.fit(X_train, y_train.logerror)\n",
    "    # fit the thing\n",
    "\n",
    "# predict train\n",
    "y_train['logerror_pred_lars'] = lars.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train_lars = median_squared_error(y_train.logerror, y_train.logerror_pred_lars)**1/2\n",
    "\n",
    "# predict validate\n",
    "y_validate['logerror_pred_lars'] = lars.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate_lars = median_squared_error(y_validate.logerror, y_validate.logerror_pred_lars)**1/2\n",
    "\n",
    "print(\"RMSE for Lasso + Lars\\nTraining/In-Sample: \", rmse_train_lars, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_lars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_validate.head()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"Baseline: Predict Using Median\", (16, 9.5))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"The Ideal Line: Predicted = Actual\", (.5, 3.5), rotation=15.5)\n",
    "\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lars, \n",
    "            alpha=.5, color=\"darkred\", s=100, label=\"Model: LinearRegression\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual Final Grade\")\n",
    "plt.ylabel(\"Predicted Final Grade\")\n",
    "plt.title(\"Where are predictions more extreme? More modest?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweedie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "glm = TweedieRegressor(power=1, alpha=0)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "glm.fit(X_train, y_train.logerror)\n",
    "\n",
    "# predict train\n",
    "y_train['logerror_pred_glm'] = glm.predict(X_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train_glm = mean_squared_error(y_train.logerror, y_train.logerror_pred_glm)**1/2\n",
    "\n",
    "# predict validate\n",
    "y_validate['logerror_pred_glm'] = glm.predict(X_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate_glm = mean_squared_error(y_validate.logerror, y_validate.logerror_pred_glm)**1/2\n",
    "\n",
    "print(\"RMSE for GLM using Tweedie, power=1 & alpha=0\\nTraining/In-Sample: \", rmse_train_glm, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_validate.head()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_mean, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"Baseline: Predict Using Median\", (16, 9.5))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"The Ideal Line: Predicted = Actual\", (.5, 3.5), rotation=15.5)\n",
    "\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_glm, \n",
    "            alpha=.5, color=\"darkviolet\", s=100, label=\"Model: TweedieRegressor\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Where are predictions more extreme? More modest?\")\n",
    "# plt.annotate(\"The polynomial model appears to overreact to noise\", (2.0, -10))\n",
    "# plt.annotate(\"The OLS model (LinearRegression)\\n appears to be most consistent\", (15.5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression degree 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree2 = pf.fit_transform(X_train)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree2 = pf.transform(X_validate)\n",
    "    # dont call fit transform just call transform\n",
    "        # we only fit train not validate\n",
    "X_test_degree2 = pf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm2.fit(X_train_degree2, y_train.logerror)\n",
    "\n",
    "# predict train\n",
    "y_train['logerror_pred_lm2'] = lm2.predict(X_train_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train_lm2 = mean_squared_error(y_train.logerror, y_train.logerror_pred_lm2)**1/2\n",
    "\n",
    "# predict validate\n",
    "y_validate['logerror_pred_lm2'] = lm2.predict(X_validate_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate_lm2 = mean_squared_error(y_validate.logerror, y_validate.logerror_pred_lm2)**1/2\n",
    "\n",
    "print(\"RMSE for Polynomial Model, degrees=2\\nTraining/In-Sample: \", rmse_train_lm2, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_lm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_validate.head()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"Baseline: Predict Using Median\", (16, 9.5))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"The Ideal Line: Predicted = Actual\", (.5, 3.5), rotation=15.5)\n",
    "\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm2, \n",
    "            alpha=.5, color=\"darkturquoise\", s=100, label=\"Model 2nd degree Polynomial\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Where are predictions more extreme? More modest?\")\n",
    "# plt.annotate(\"The polynomial model appears to overreact to noise\", (2.0, -10))\n",
    "# plt.annotate(\"The OLS model (LinearRegression)\\n appears to be most consistent\", (15.5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression degree 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf3 = PolynomialFeatures(degree=3)\n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree3 = pf3.fit_transform(X_train)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree3 = pf3.transform(X_validate)\n",
    "    # dont call fit transform just call transform\n",
    "        # we only fit train not validate\n",
    "X_test_degree3 = pf3.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lm3 = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm3.fit(X_train_degree3, y_train.logerror)\n",
    "\n",
    "# predict train\n",
    "y_train['logerror_pred_lm3'] = lm3.predict(X_train_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train_lm3 = mean_squared_error(y_train.logerror, y_train.logerror_pred_lm2)**1/2\n",
    "\n",
    "# predict validate\n",
    "y_validate['logerror_pred_lm3'] = lm3.predict(X_validate_degree3)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate_lm3 = mean_squared_error(y_validate.logerror, y_validate.logerror_pred_lm2)**1/2\n",
    "\n",
    "print(\"RMSE for Polynomial Model, degrees=2\\nTraining/In-Sample: \", rmse_train_lm3, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_lm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_validate.head()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"Baseline: Predict Using Median\", (16, 9.5))\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.annotate(\"The Ideal Line: Predicted = Actual\", (.5, 3.5), rotation=15.5)\n",
    "\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm3, \n",
    "            alpha=.5, color=\"darkturquoise\", s=100, label=\"Model 2nd degree Polynomial\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Where are predictions more extreme? More modest?\")\n",
    "# plt.annotate(\"The polynomial model appears to overreact to noise\", (2.0, -10))\n",
    "# plt.annotate(\"The OLS model (LinearRegression)\\n appears to be most consistent\", (15.5, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(6, 1, figsize=(8,22), sharey=True)\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "plt.subplot(6,1,1)\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm, \n",
    "            alpha=.5, color=\"mediumblue\", s=100, label=\"Model: LinearRegression\")\n",
    "m, b = np.polyfit(y_validate.logerror, y_validate.logerror_pred_lm, 1)\n",
    "plt.plot(y_validate.logerror, m*y_validate.logerror+b, color='fuchsia', label='Line of Regrssion')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='Baseline')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"cyan\", label='OLS Regession')\n",
    "plt.title('Model: LinearRegression')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "plt.subplot(6,1,2)\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_glm, \n",
    "            alpha=.5, color=\"teal\", s=100, label=\"Model: TweedieRegressor\")\n",
    "m, b = np.polyfit(y_validate.logerror, y_validate.logerror_pred_glm, 1) \n",
    "plt.plot(y_validate.logerror, m*y_validate.logerror+b, color='fuchsia', label='Line of Regrssion')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='Baseline')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"cyan\", label='OLS Regression')\n",
    "plt.title('Model: TweedieRegressor')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "plt.subplot(6,1,3)\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm, \n",
    "            alpha=.5, color=\"limegreen\", s=100, label=\"Model 2nd degree Polynomial\")\n",
    "\n",
    "m, b = np.polyfit(y_validate.logerror, y_validate.logerror_pred_lm2, 1) \n",
    "plt.plot(y_validate.logerror, m*y_validate.logerror+b, color='fuchsia', label='Line of Regrssion')\n",
    "\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='Baseline')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"cyan\", label='OLS Regression')\n",
    "plt.title('Model 2nd degree Polynomial')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "plt.subplot(5,1,3)\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm3, \n",
    "            alpha=.5, color=\"limegreen\", s=100, label=\"Model 3rd degree Polynomial\")\n",
    "\n",
    "m, b = np.polyfit(y_validate.logerror, y_validate.logerror_pred_lm3, 1) \n",
    "plt.plot(y_validate.logerror, m*y_validate.logerror+b, color='fuchsia', label='Line of Regrssion')\n",
    "\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='Baseline')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"cyan\", label='OLS Regression')\n",
    "plt.title('Model 2nd degree Polynomial')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "\n",
    "plt.subplot(6,1,4)\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lars, \n",
    "            alpha=.5, color=\"yellow\", s=100, label=\"Model: Lasso\")\n",
    "\n",
    "m, b = np.polyfit(y_validate.logerror, y_validate.logerror_pred_lars, 1) \n",
    "plt.plot(y_validate.logerror, m*y_validate.logerror+b, color='fuchsia', label='Line of Regrssion')\n",
    "\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='Baseline')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"cyan\", label='OLS Regression')\n",
    "plt.title('Model: Lasso')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "\n",
    "plt.subplot(6,1,5)\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lars, \n",
    "            alpha=.5, color=\"yellow\", s=100, label=\"Model: Lasso\")\n",
    "\n",
    "m, b = np.polyfit(y_validate.logerror, y_validate.logerror_pred_lars, 1) \n",
    "plt.plot(y_validate.logerror, m*y_validate.logerror+b, color='fuchsia', label='Line of Regrssion')\n",
    "\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='Baseline')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"cyan\", label='OLS Regression')\n",
    "plt.title('Model: Lasso')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(6,1,6)\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='Baseline')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"cyan\", label='OLS Regression')\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm, \n",
    "            alpha=.5, color=\"mediumblue\", s=100, label=\"Model: LinearRegression\")\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_glm, \n",
    "            alpha=.5, color=\"teal\", s=100, label=\"Model: TweedieRegressor\")\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lm2, \n",
    "            alpha=.5, color=\"yellow\", s=100, label=\"Model 2nd degree Polynomial\")\n",
    "plt.scatter(y_validate.logerror, y_validate.logerror_pred_lars, \n",
    "            alpha=.5, color=\"limegreen\", s=100, label=\"Model: Lasso\")\n",
    "\n",
    "plt.plot(y_validate.logerror, y_validate.logerror_pred_median, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.plot(y_validate.logerror, y_validate.logerror, alpha=.5, color=\"black\", label='_nolegend_')\n",
    "plt.title('All Models stacked')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE using Mean\\nTrain/In-Sample: \", round(rmse_train_mean, 2), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate_mean, 2))\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"RMSE using Median\\nTrain/In-Sample: \", round(rmse_train_medium, 2), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate_medium, 2))\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"RMSE for OLS using LinearRegression\\nTraining/In-Sample: \", rmse_train_lm, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_lm)\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"RMSE for Lasso + Lars\\nTraining/In-Sample: \", rmse_train_lars, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_lars)\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"RMSE for GLM using Tweedie, power=1 & alpha=0\\nTraining/In-Sample: \", rmse_train_glm, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_glm)\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"RMSE for Polynomial Model, degrees=2\\nTraining/In-Sample: \", rmse_train_lm2, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_lm2)\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"RMSE for Polynomial Model, degrees=3\\nTraining/In-Sample: \", rmse_train_lm3, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate_lm3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
